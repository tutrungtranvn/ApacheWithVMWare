# ***INSTALL APACHE HADOOP AND RUN WORDCOUNT EXAMPLE ON VMWARE***

## *1. INTRODUCTION*

   ### **What is Hadoop?**

   > Hadoop is an Apache open source framework written in java that allows distributed processing of large datasets across clusters of computers using simple programming models. The Hadoop framework application works in an environment that provides distributed storage and computation across clusters of computers. Hadoop is designed to scale up from single server to thousands of machines, each offering local computation and storage.
   
   ### **What is MapReduce?**
   
   > MapReduce is a parallel programming model for writing distributed applications devised at Google for efficient processing of large amounts of data (multi-terabyte data-sets), on large clusters (thousands of nodes) of commodity hardware in a reliable, fault-tolerant manner. The MapReduce program runs on Hadoop which is an Apache open-source framework.
   
   ### **What is Hadoop Distributed File System?**
   > The Hadoop Distributed File System (HDFS) is based on the Google File System (GFS) and provides a distributed file system that is designed to run on commodity hardware. It has many similarities with existing distributed file systems. However, the differences from other distributed file systems are significant. It is highly fault-tolerant and is designed to be deployed on low-cost hardware. It provides high throughput access to application data and is suitable for applications having large datasets.
   >
> Apart from the above-mentioned two core components, Hadoop framework also includes the following two modules:
>
> * Hadoop Common − These are Java libraries and utilities required by other Hadoop modules.
>
> * Hadoop YARN − This is a framework for job scheduling and cluster resource management.
   >
 ## *2. INSTALLATION*
 
 
 
 
